/*
 *  coroutine_call() in i386 assembly.
 *
 *  Using Gnu AS as the assembler as it allows gcc portability and a
 *  single toolchain. The call and yield parts have to be in assembly.
 *
 *  Distribution and use of this software are as per the terms of the
 *  Simplified BSD License (also known as the "2-Clause License")
 *
 *  Copyright 2014 Conor F. O'Rourke. All rights reserved.
 *
 *
 *  ABI is Intel X86 32 bit: you can change eax, ecx, edx in a function.
 *  By extension, any function you call can willfully change these.
 *
 *  On ELF, the C calling convention does not have leading underscores,
 *  On Win32 it does. Fastcall uses @ name decoration, ELF doesn't allow
 *  that symbol.
 *
 *  Gcc, for some reason, wants function calls to be made with a 16-byte
 *  aligned stack. The stack is aligned before the call. The call itself will,
 *  of course, promptly unalign the stack by the size of the return address.
 */

.intel_syntax noprefix      /* Intel syntax ftw */


#if !defined(__i386__) || defined(_WIN64)
        .error "This code runs on 32 bit x86 only"
#endif


#include "coroutine.inc"


        EAGAIN = 11

#ifdef _WIN32
        WINTIB_STACKHI = 0x04
        WINTIB_STACKLO = 0x08
        WINTIB_TIBADDR = 0x18
#endif


        /*
         *  Code section, read only
         */

        .text


#if defined(_WIN32) || defined(__APPLE__)
        /* Global calls have leading underscores */
        #define     coroutine_checkcontext  _coroutine_checkcontext
        #define     coroutine_call          _coroutine_call
#endif

        .extern     coroutine_checkcontext
        .global     coroutine_call


/**
 *  coroutine_call (__cdecl) - Call or yield back to the coroutine
 *
 *  Takes the opaque pointer to the allocated context block and calls or
 *  yields back into the context coroutine. The coroutine can:
 *
 *    - call coroutine_yield to yield back here, in which case the return
 *      value is always -EAGAIN and coroutine_hasended() returns false or
 *
 *    - exit normally with a return code, in which case the return value
 *      is that return code and coroutine_hasended() returns true.
 *
 *  In the former case, this call will yield back to the instruction
 *  following the call to coroutine_yield().
 *
 *  Given that I can clearly detect where I am, I've decided to merge
 *  coroutine_call and coroutine_yield into the same function - they
 *  take the same argument and can be distinguished by .onvstack member.
 *
 *  Returns: -EAGAIN on yield back from coroutine_call
 *           0 on return from coroutine_yield()
 *  Panics on error
 */

coroutine_call:

        push    ebp
        mov     ebp, esp

        /*  gcc wants a 16 byte stack alignment in any call
         *  C calls may destroy any ABI register
         *  coroutine_checkcontext() will panic on failure
         */

        mov     ecx, [ebp + 8]                  /* Context struct */

        mov     eax, 0                          /* Align          */
        push    eax
        push    ecx                             /* push coctx @16 */
        call    coroutine_checkcontext
        add     esp, 8                          /* double pop     */

        mov     ecx, [ebp + 8]                  /* ECX -> context */


        /*  ECX -> coroutine context structure
         *
         *  Who are we? call() or yield()? .onvstack decides.
         */

        cmp     dword ptr [ecx + CTX_ONVSTACK], 0
        jne     Coyield_function_enter


        /*
         *  On the normal stack: this is "coroutine_call()"
         *                       --------------------------
         *  Normal stack looks like:
         *      [...] [context ptr] [ret to main] [ebp]
         *
         *  Have we previously yielded from the coroutine?
         */

        cmp     dword ptr [ecx + CTX_YIELDED], 0
        jne     Cocall_had_yielded


        /*
         *  Not yielded. coroutine call starts from the beginning
         *  .cofunction, .vstacklow, .vstackhigh are set
         */

        mov     eax, [ecx + CTX_COFUNCTION]     /* .nextjump is to the */
        mov     [ecx + CTX_NEXTJUMP], eax       /* start of coroutine  */


        /*  Blank aligned vstack. We want the following:
         *
         *      [context pointer] <---- aligned on 16 bytes
         *      [return address]  <---- set to Cocall_returnpoint
         *               ^------------- .otherstack points here
         */

        mov     eax, [ecx + CTX_VSTACKHIGH]     /* EAX -> vstack         */
        sub     eax, 16                         /* align vstack and      */
        mov     [eax], ecx                      /* vpush context pointer */

        sub     eax, 4
        lea     edx, Cocall_returnpoint
        mov     [eax], edx                      /* vpush return address */

        mov     [ecx + CTX_OTHERSTACK], eax     /* .otherstack = vstack */

        /* Now .nextjump -> coroutine, .otherstack -> vstack */


Cocall_had_yielded:

        /*
         *  Save state - push everything to normal stack. Leave the
         *  segment registers alone. Push the NT_TIB stack boundaries
         *  (currently set to normal stack) as we'll be changing them
         */

#ifdef _WIN32
        mov     edx, FS:[WINTIB_TIBADDR]        /* EDX -> NT_TIB */
        push    dword ptr [edx + WINTIB_STACKHI]
        push    dword ptr [edx + WINTIB_STACKLO]
#endif
        pushad

        /* Swap stacks: normal to vstack */

        mov     eax, [ecx + CTX_OTHERSTACK]     /* EAX -> vstack    */
        mov     [ecx + CTX_OTHERSTACK], esp     /* otherstack = ESP */
        mov     esp, eax                        /* BAM! Stack swap  */

        mov     dword ptr [ecx + CTX_ONVSTACK], 1


        /* Using the vstack now */
        /* Set NT_TIB ranges to the vstack */

#ifdef _WIN32
        mov     eax, [ecx + CTX_VSTACKHIGH]
        mov     [edx + WINTIB_STACKHI], eax
        mov     eax, [ecx + CTX_VSTACKLOW]
        mov     [edx + WINTIB_STACKLO], eax
#endif

        /* .nextjump points into the coroutine */

        push    dword ptr [ecx + CTX_NEXTJUMP]  /* Using ret to jump */

        lea     eax, Cocall_returnpoint
        mov     [ecx + CTX_NEXTJUMP], eax

        /* .nextjump -> Cocall_returnpoint, .otherstack -> normal stack */

        ret                                     /* jump into coroutine */


Cocall_returnpoint:

        /* Back from coroutine and on the virtual stack. We have:

           - A normal return. The ret pop'ed the return address and the
             next and last thing on the stack is the context pointer.
             EAX will contain the return value so save that first.

           - A yield. The yield must push the context pointer onto the
             stack just before it leaps back here. .yielded is true and
             no register values are valid. yield() sets EAX to -EAGAIN.
        */

        pop     ecx                             /* ECX -> context struct */

        mov     [ecx + CTX_RETVALUE], eax       /* Save possible ret val */


        /* Swap stacks: vstack to normal */

        mov     eax, [ecx + CTX_OTHERSTACK]     /* EAX -> normal stack */
        mov     [ecx + CTX_OTHERSTACK], esp     /* otherstack = ESP    */
        mov     esp, eax                        /* ESP = normal stack  */

        mov     dword ptr [ecx + CTX_ONVSTACK], 0


        /*  Back on the normal stack which contains:
         *
         *      [context ptr][ret to main][ebp]
         *      [NT normal stackhi][NT normal stacklo]   (if _WIN32)
         *      [EAX, ECX, EDX, EBX, ESP, EBP, ESI, EDI]
         *
         *  Push state is that at the "Cocall_had_yielded:" label where:
         *
         *      EDX -> NT_TIB, ECX -> context struct, EAX unknown
         */

        popad

#ifdef _WIN32
        pop     dword ptr [edx + WINTIB_STACKLO]
        pop     dword ptr [edx + WINTIB_STACKHI]
#endif

        /* Set return value and exit */

        mov     eax, [ecx + CTX_RETVALUE]
        pop     ebp
        ret




Coyield_function_enter:

        /*
         *  On the virtual stack: this is "coroutine_yield()"
         *                        ---------------------------
         *  Vstack looks like:
         *      [context ptr]
         *        [ret back to Cocall_returnpoint]
         *      [local coroutine variables]
         *      [context ptr]
         *        [ret back to coroutine]
         *      [ebp]
         *
         *  And ECX -> coroutine context structure
         */

        mov     dword ptr [ecx + CTX_YIELDED], 1

        pushad                                  /* Push all registers       */
        push    ecx                             /* See @Cocall_returnpoint  */

        /* .nextjump points to Cocall_returnpoint */

        push    dword ptr [ecx + CTX_NEXTJUMP]  /* Using ret to jump */

        lea     eax, Coyield_coresume
        mov     [ecx + CTX_NEXTJUMP], eax

        /* .nextjump -> Coyield_coresume */

        mov     eax, -EAGAIN                    /* Return value and jump */
        ret                                     /* to Cocall_returnpoint */


Coyield_coresume:

        /*
         *  coroutine_call() resumes coroutine running by jumping here.
         *
         *  On virtual stack which is as above but with registers saved:
         *      [.....]
         *      [ret back to coroutine]
         *      [ebp]
         *      [all registers]     (pushed ECX pointed to context struct)
         */

        popad
        mov     dword ptr [ecx + CTX_YIELDED], 0
        mov     eax, 0
        pop     ebp
        ret




.att_syntax


/* end */
